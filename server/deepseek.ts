/*
// server/deepseek.ts
import { OpenAI } from 'openai';
import { config } from 'dotenv';

config();

// ä½¿ç”¨ DeepSeek æ›¿æ¢åŸæœ‰çš„ OpenAI
const deepseek = new OpenAI({
  baseURL: process.env.DEEPSEEK_API_BASE || 'https://api.deepseek.com',
  apiKey: process.env.DEEPSEEK_API_KEY
});

export interface MemoryForStory {
  displayName: string;
  note: string;
  photoUrl: string;
}

export interface PhotoCaption {
  photoUrl: string;
  caption: string;
  emoji: string;
}

export async function generateMemoryStory(memories: MemoryForStory[]): Promise<{ title: string; captions: PhotoCaption[] }> {
  const memoriesText = memories.map((m, idx) => 
    `Photo ${idx + 1} by ${m.displayName}: "${m.note}"\nPhoto URL: ${m.photoUrl}`
  ).join('\n\n');

  const prompt = `You are creating a visual scrapbook-style memory book from uploaded photos and notes. Each photo needs a short, poetic caption that captures the moment.

Your task is to generate short captions (max 20 words each) for each photo that feel human, calm, and reflective.

## CAPTION STYLE:

1. **Short & poetic** (max 20 words)
   - Calm, reflective tone
   - Reference what's in the note
   - Add appropriate emoji at the end

2. **Emotional tone by scenario**:
   - Travel â†’ "The sunlight fell perfectly on this street ğŸŒ¿"
   - Daily Life â†’ "Quiet moments before everything began"
   - Events â†’ "We laughed too much to take this photo seriously ğŸ˜‚"
   - Work/Project â†’ "Progress felt slow, but we kept going ğŸ’¼"
   - Study â†’ "Finally understanding after hours of trying ğŸ“š"
   - Friendship â†’ "The best kind of afternoon â˜•"

3. **Keep it natural**:
   - No over-explanation
   - Reference the user's note content
   - Match the mood of the moment

## EXAMPLES:

**Travel:**
- Caption: "The mountains looked endless from here, cold wind but warm sun ğŸ”"
- Caption: "Found this quiet path just before sunset ğŸŒ…"

**Daily Life:**
- Caption: "Morning coffee by the window, nothing special, just peace â˜•"
- Caption: "The light was soft, the world still waking up ğŸŒ¤"

**Events:**
- Caption: "Everyone arrived at once, laughter everywhere ğŸ‰"
- Caption: "By midnight, just us and the quiet ğŸŒ™"

**Friendship:**
- Caption: "Same spot, same drinks, always feels like home â˜•"
- Caption: "Walking back, not wanting it to end ğŸ’¬"

---

Here are the photos and notes:

${memoriesText}

Format your response as JSON:
{
  "title": "Simple title for the memory book (e.g., 'Weekend Memories', 'Our Days Together')",
  "captions": [
    {
      "photoUrl": "exact photo URL from above",
      "caption": "short caption (max 20 words)",
      "emoji": "single emoji that fits the mood"
    }
  ]
}

Generate a caption for EACH photo. Match the emotional tone to the context. Keep captions short, natural, and grounded.`;

  try {
    console.log('ğŸ§  ä½¿ç”¨ DeepSeek ç”Ÿæˆè®°å¿†æ•…äº‹...');
    
    const response = await deepseek.chat.completions.create({
      model: "deepseek-chat",
      messages: [{ role: "user", content: prompt }],
      response_format: { type: "json_object" },
      max_tokens: 1500,
    });

    const result = JSON.parse(response.choices[0]?.message?.content || "{}");
    
    console.log('âœ… DeepSeek ç”ŸæˆæˆåŠŸ');
    return {
      title: result.title || "Our Memory Book",
      captions: result.captions || [],
    };
    
  } catch (error: any) {
    console.error('âŒ DeepSeek ç”Ÿæˆå¤±è´¥:', error.message);
    
    // ä¼˜é›…é™çº§ï¼šè¿”å›é»˜è®¤å†…å®¹
    return getFallbackMemoryStory(memories);
  }
}

// ä¼˜é›…é™çº§æ–¹æ¡ˆ
function getFallbackMemoryStory(memories: MemoryForStory[]): { title: string; captions: PhotoCaption[] } {
  console.log('ğŸ”„ ä½¿ç”¨é™çº§æ–¹æ¡ˆç”Ÿæˆè®°å¿†æ•…äº‹');
  
  const fallbackTitles = [
    "çè´µå›å¿†",
    "ç¾å¥½æ—¶å…‰", 
    "è®°å¿†ç¢ç‰‡",
    "ç”Ÿæ´»ç¬é—´",
    "æˆ‘ä»¬çš„æ•…äº‹"
  ];
  
  const fallbackCaptions = [
    { text: "é˜³å…‰æ­£å¥½ï¼Œå¿ƒæƒ…å¾ˆç¾ ğŸŒ", emoji: "ğŸŒ" },
    { text: "æ¸©æš–çš„æ—¥å¸¸æ—¶åˆ» â˜€ï¸", emoji: "â˜€ï¸" },
    { text: "å€¼å¾—çè—çš„ç¬é—´ âœ¨", emoji: "âœ¨" },
    { text: "ç®€å•è€Œç¾å¥½çš„æ—¥å­ ğŸŒˆ", emoji: "ğŸŒˆ" },
    { text: "ç”Ÿæ´»ä¸­çš„å°ç¡®å¹¸ ğŸ’«", emoji: "ğŸ’«" },
    { text: "éš¾å¿˜çš„ç›¸èšæ—¶å…‰ ğŸ‘«", emoji: "ğŸ‘«" },
    { text: "å®é™çš„åˆåæ—¶å…‰ ğŸƒ", emoji: "ğŸƒ" },
    { text: "å¿«ä¹çš„è®°å¿†ç¢ç‰‡ ğŸˆ", emoji: "ğŸˆ" }
  ];

  const title = fallbackTitles[Math.floor(Math.random() * fallbackTitles.length)];
  
  const captions = memories.map((memory, index) => {
    const fallback = fallbackCaptions[index % fallbackCaptions.length];
    return {
      photoUrl: memory.photoUrl,
      caption: memory.note ? `${memory.note} ${fallback.text}` : fallback.text,
      emoji: fallback.emoji
    };
  });

  return { title, captions };
}

// å¯¼å‡ºåŸæœ‰æ¥å£ä»¥ä¿æŒå…¼å®¹æ€§
export default {
  generateMemoryStory
};

*/
// âš ï¸ ä¸´æ—¶ç¦ç”¨ DeepSeek æ¨¡å—ï¼Œé¿å…è¦æ±‚ OPENAI_API_KEY
console.warn("âš ï¸ DeepSeek æ¨¡å—å·²ç¦ç”¨ã€‚");

export default null;
